{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13bae479-b038-47e1-86b4-a4400d7744b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install this before running the notebook\n",
    "# !pip install h2o\n",
    "# !pip install autogluon.tabular[all]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1505b12-b8a3-46c1-be11-316e939e83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "663fff0c-23fb-4914-8863-a5c36f796e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f05891-e7ba-4289-96e6-d6001c177cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_Coil_S_1</th>\n",
       "      <th>I_Coil_S_2</th>\n",
       "      <th>I_Coil_S_3</th>\n",
       "      <th>I_Coil_S_4</th>\n",
       "      <th>I_Coil_S_5</th>\n",
       "      <th>I_Coil_S_6</th>\n",
       "      <th>I_Coil_S_7</th>\n",
       "      <th>I_Coil_S_8</th>\n",
       "      <th>I_Coil_S_9</th>\n",
       "      <th>I_Coil_S_10</th>\n",
       "      <th>I_Coil_S_11</th>\n",
       "      <th>I_Coil_S_12</th>\n",
       "      <th>I_Coil_S_13</th>\n",
       "      <th>I_Coil_S_14</th>\n",
       "      <th>I_Coil_S_15</th>\n",
       "      <th>I_Coil_S_16</th>\n",
       "      <th>I_Coil_S_17</th>\n",
       "      <th>I_Coil_S_18</th>\n",
       "      <th>I_Coil_S_19</th>\n",
       "      <th>I_Coil_S_20</th>\n",
       "      <th>I_Coil_S_21</th>\n",
       "      <th>I_Coil_S_22</th>\n",
       "      <th>I_Coil_S_23</th>\n",
       "      <th>I_Coil_S_24</th>\n",
       "      <th>I_Coil_S_25</th>\n",
       "      <th>I_Coil_S_26</th>\n",
       "      <th>I_Coil_S_27</th>\n",
       "      <th>I_Coil_S_28</th>\n",
       "      <th>I_Coil_S_29</th>\n",
       "      <th>I_Coil_S_30</th>\n",
       "      <th>T_R_Core</th>\n",
       "      <th>T_R_Core_2</th>\n",
       "      <th>T_R_Core_3</th>\n",
       "      <th>T_R_Core_4</th>\n",
       "      <th>T_R_Core_5</th>\n",
       "      <th>T_R_Core_6</th>\n",
       "      <th>T_R_Core_7</th>\n",
       "      <th>T_R_Core_8</th>\n",
       "      <th>T_R_Core_9</th>\n",
       "      <th>T_R_Core_10</th>\n",
       "      <th>T_R_Core_11</th>\n",
       "      <th>T_R_Core_12</th>\n",
       "      <th>T_R_Core_13</th>\n",
       "      <th>T_R_Core_14</th>\n",
       "      <th>T_R_Core_15</th>\n",
       "      <th>T_R_Core_16</th>\n",
       "      <th>T_R_Core_17</th>\n",
       "      <th>T_R_Core_18</th>\n",
       "      <th>T_R_Core_19</th>\n",
       "      <th>T_R_Core_20</th>\n",
       "      <th>T_R_Core_21</th>\n",
       "      <th>T_R_Core_22</th>\n",
       "      <th>T_R_Core_23</th>\n",
       "      <th>T_R_Core_24</th>\n",
       "      <th>T_R_Core_25</th>\n",
       "      <th>T_R_Core_26</th>\n",
       "      <th>T_R_Core_27</th>\n",
       "      <th>T_R_Core_28</th>\n",
       "      <th>Rotor_posn</th>\n",
       "      <th>Net_Torque</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>838.911750</td>\n",
       "      <td>759.710510</td>\n",
       "      <td>151.419436</td>\n",
       "      <td>1615.056972</td>\n",
       "      <td>743.575343</td>\n",
       "      <td>391.038655</td>\n",
       "      <td>1261.606568</td>\n",
       "      <td>242.427231</td>\n",
       "      <td>1517.168814</td>\n",
       "      <td>1235.880686</td>\n",
       "      <td>1136.968086</td>\n",
       "      <td>1644.552590</td>\n",
       "      <td>1299.043478</td>\n",
       "      <td>373.753114</td>\n",
       "      <td>1154.363677</td>\n",
       "      <td>968.558844</td>\n",
       "      <td>475.046566</td>\n",
       "      <td>1728.383799</td>\n",
       "      <td>695.624587</td>\n",
       "      <td>1451.133024</td>\n",
       "      <td>805.648549</td>\n",
       "      <td>1142.269616</td>\n",
       "      <td>200.665408</td>\n",
       "      <td>1902.587556</td>\n",
       "      <td>601.935652</td>\n",
       "      <td>40.713244</td>\n",
       "      <td>1532.422884</td>\n",
       "      <td>1856.700587</td>\n",
       "      <td>418.592063</td>\n",
       "      <td>955.759736</td>\n",
       "      <td>15.479226</td>\n",
       "      <td>-42.847403</td>\n",
       "      <td>6.064716</td>\n",
       "      <td>-12.895680</td>\n",
       "      <td>18.252286</td>\n",
       "      <td>-29.389699</td>\n",
       "      <td>11.222207</td>\n",
       "      <td>-26.003880</td>\n",
       "      <td>-21.294832</td>\n",
       "      <td>31.174374</td>\n",
       "      <td>-29.326844</td>\n",
       "      <td>112.638421</td>\n",
       "      <td>-24.577963</td>\n",
       "      <td>24.606552</td>\n",
       "      <td>4.854151</td>\n",
       "      <td>-57.440308</td>\n",
       "      <td>27.289150</td>\n",
       "      <td>-117.839598</td>\n",
       "      <td>37.453612</td>\n",
       "      <td>-47.446869</td>\n",
       "      <td>17.398821</td>\n",
       "      <td>-26.851500</td>\n",
       "      <td>-28.688864</td>\n",
       "      <td>-13.777332</td>\n",
       "      <td>-11.467442</td>\n",
       "      <td>122.742396</td>\n",
       "      <td>-14.451273</td>\n",
       "      <td>10.036495</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>-65.087081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.159728</td>\n",
       "      <td>1145.927954</td>\n",
       "      <td>1657.822801</td>\n",
       "      <td>304.390164</td>\n",
       "      <td>494.859837</td>\n",
       "      <td>1807.131972</td>\n",
       "      <td>1049.181833</td>\n",
       "      <td>94.704052</td>\n",
       "      <td>489.101852</td>\n",
       "      <td>426.085510</td>\n",
       "      <td>358.871208</td>\n",
       "      <td>1578.618173</td>\n",
       "      <td>314.545535</td>\n",
       "      <td>612.220245</td>\n",
       "      <td>636.828373</td>\n",
       "      <td>622.404727</td>\n",
       "      <td>404.759696</td>\n",
       "      <td>1805.421913</td>\n",
       "      <td>1690.866852</td>\n",
       "      <td>1461.239642</td>\n",
       "      <td>280.030105</td>\n",
       "      <td>1460.276274</td>\n",
       "      <td>5.973251</td>\n",
       "      <td>268.499457</td>\n",
       "      <td>870.218774</td>\n",
       "      <td>570.007014</td>\n",
       "      <td>1128.917385</td>\n",
       "      <td>703.853609</td>\n",
       "      <td>597.595272</td>\n",
       "      <td>1904.930449</td>\n",
       "      <td>11.229471</td>\n",
       "      <td>-12.536256</td>\n",
       "      <td>30.446560</td>\n",
       "      <td>-103.580160</td>\n",
       "      <td>20.265228</td>\n",
       "      <td>17.454621</td>\n",
       "      <td>19.543563</td>\n",
       "      <td>-38.937267</td>\n",
       "      <td>-10.905801</td>\n",
       "      <td>13.979060</td>\n",
       "      <td>-8.572148</td>\n",
       "      <td>112.500900</td>\n",
       "      <td>-8.759866</td>\n",
       "      <td>25.504916</td>\n",
       "      <td>0.290484</td>\n",
       "      <td>-40.982595</td>\n",
       "      <td>41.326342</td>\n",
       "      <td>-100.186679</td>\n",
       "      <td>26.732960</td>\n",
       "      <td>-66.229009</td>\n",
       "      <td>9.483419</td>\n",
       "      <td>-44.946565</td>\n",
       "      <td>-8.622409</td>\n",
       "      <td>27.807482</td>\n",
       "      <td>-15.351617</td>\n",
       "      <td>82.259023</td>\n",
       "      <td>-10.616755</td>\n",
       "      <td>31.961057</td>\n",
       "      <td>-1.175758</td>\n",
       "      <td>0.557958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>604.895390</td>\n",
       "      <td>1687.818115</td>\n",
       "      <td>1012.687243</td>\n",
       "      <td>1502.671404</td>\n",
       "      <td>405.011494</td>\n",
       "      <td>1454.313326</td>\n",
       "      <td>589.616445</td>\n",
       "      <td>1840.587726</td>\n",
       "      <td>21.227596</td>\n",
       "      <td>353.216915</td>\n",
       "      <td>1263.009765</td>\n",
       "      <td>1345.094191</td>\n",
       "      <td>1366.001321</td>\n",
       "      <td>110.808211</td>\n",
       "      <td>729.066266</td>\n",
       "      <td>1374.909432</td>\n",
       "      <td>153.261000</td>\n",
       "      <td>279.744488</td>\n",
       "      <td>658.661727</td>\n",
       "      <td>1519.840001</td>\n",
       "      <td>1756.416608</td>\n",
       "      <td>1286.093196</td>\n",
       "      <td>501.047096</td>\n",
       "      <td>1929.647805</td>\n",
       "      <td>974.581579</td>\n",
       "      <td>129.650555</td>\n",
       "      <td>1607.304410</td>\n",
       "      <td>820.807789</td>\n",
       "      <td>1824.520892</td>\n",
       "      <td>473.856855</td>\n",
       "      <td>17.637504</td>\n",
       "      <td>-31.529522</td>\n",
       "      <td>15.031434</td>\n",
       "      <td>-49.240416</td>\n",
       "      <td>15.424546</td>\n",
       "      <td>5.433440</td>\n",
       "      <td>13.185292</td>\n",
       "      <td>38.785119</td>\n",
       "      <td>-19.140526</td>\n",
       "      <td>20.559278</td>\n",
       "      <td>-7.332849</td>\n",
       "      <td>97.164002</td>\n",
       "      <td>-16.685405</td>\n",
       "      <td>5.809139</td>\n",
       "      <td>6.244711</td>\n",
       "      <td>-75.382638</td>\n",
       "      <td>-5.592654</td>\n",
       "      <td>-13.735950</td>\n",
       "      <td>50.292172</td>\n",
       "      <td>-13.282855</td>\n",
       "      <td>17.478178</td>\n",
       "      <td>-22.011852</td>\n",
       "      <td>-25.213906</td>\n",
       "      <td>8.814699</td>\n",
       "      <td>-19.264357</td>\n",
       "      <td>130.770247</td>\n",
       "      <td>-13.454053</td>\n",
       "      <td>36.582125</td>\n",
       "      <td>-1.151515</td>\n",
       "      <td>167.344904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.840346</td>\n",
       "      <td>1759.438076</td>\n",
       "      <td>1574.016330</td>\n",
       "      <td>212.658270</td>\n",
       "      <td>330.123381</td>\n",
       "      <td>1857.333290</td>\n",
       "      <td>970.880979</td>\n",
       "      <td>224.690144</td>\n",
       "      <td>1995.096232</td>\n",
       "      <td>1716.554497</td>\n",
       "      <td>938.142312</td>\n",
       "      <td>231.825997</td>\n",
       "      <td>574.401833</td>\n",
       "      <td>312.836168</td>\n",
       "      <td>1135.919141</td>\n",
       "      <td>1026.209542</td>\n",
       "      <td>1396.933967</td>\n",
       "      <td>1093.977710</td>\n",
       "      <td>1367.545965</td>\n",
       "      <td>1917.831175</td>\n",
       "      <td>823.392415</td>\n",
       "      <td>595.425860</td>\n",
       "      <td>1878.078629</td>\n",
       "      <td>1205.817297</td>\n",
       "      <td>597.432528</td>\n",
       "      <td>858.841403</td>\n",
       "      <td>343.724064</td>\n",
       "      <td>882.827033</td>\n",
       "      <td>445.642094</td>\n",
       "      <td>1678.188694</td>\n",
       "      <td>12.994437</td>\n",
       "      <td>-6.987048</td>\n",
       "      <td>24.382430</td>\n",
       "      <td>-80.895173</td>\n",
       "      <td>16.929088</td>\n",
       "      <td>35.475627</td>\n",
       "      <td>7.852790</td>\n",
       "      <td>-11.329015</td>\n",
       "      <td>-17.989747</td>\n",
       "      <td>53.259204</td>\n",
       "      <td>-40.250328</td>\n",
       "      <td>25.070360</td>\n",
       "      <td>-0.386462</td>\n",
       "      <td>7.051670</td>\n",
       "      <td>10.609738</td>\n",
       "      <td>-65.145659</td>\n",
       "      <td>22.312188</td>\n",
       "      <td>-42.883271</td>\n",
       "      <td>46.302679</td>\n",
       "      <td>-69.812219</td>\n",
       "      <td>4.260714</td>\n",
       "      <td>57.851876</td>\n",
       "      <td>-41.122330</td>\n",
       "      <td>13.443905</td>\n",
       "      <td>-17.304365</td>\n",
       "      <td>29.278734</td>\n",
       "      <td>-2.543550</td>\n",
       "      <td>5.425467</td>\n",
       "      <td>-1.127273</td>\n",
       "      <td>-24.148261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>309.189519</td>\n",
       "      <td>1211.884724</td>\n",
       "      <td>1241.877155</td>\n",
       "      <td>1765.598706</td>\n",
       "      <td>958.032189</td>\n",
       "      <td>180.943129</td>\n",
       "      <td>1683.015986</td>\n",
       "      <td>1804.044797</td>\n",
       "      <td>1496.436842</td>\n",
       "      <td>1253.418474</td>\n",
       "      <td>1899.860847</td>\n",
       "      <td>1739.772124</td>\n",
       "      <td>860.744173</td>\n",
       "      <td>9.266228</td>\n",
       "      <td>829.254146</td>\n",
       "      <td>643.718123</td>\n",
       "      <td>404.240796</td>\n",
       "      <td>1258.558023</td>\n",
       "      <td>1777.273983</td>\n",
       "      <td>630.647459</td>\n",
       "      <td>1237.191367</td>\n",
       "      <td>459.165193</td>\n",
       "      <td>803.252614</td>\n",
       "      <td>937.639814</td>\n",
       "      <td>1289.839030</td>\n",
       "      <td>338.787254</td>\n",
       "      <td>61.456967</td>\n",
       "      <td>1785.606285</td>\n",
       "      <td>1092.452883</td>\n",
       "      <td>835.650610</td>\n",
       "      <td>15.827835</td>\n",
       "      <td>-28.320735</td>\n",
       "      <td>36.028130</td>\n",
       "      <td>-32.938019</td>\n",
       "      <td>21.500328</td>\n",
       "      <td>-36.722931</td>\n",
       "      <td>-10.237192</td>\n",
       "      <td>39.495440</td>\n",
       "      <td>-44.268432</td>\n",
       "      <td>59.057567</td>\n",
       "      <td>-10.266856</td>\n",
       "      <td>76.100659</td>\n",
       "      <td>-17.603028</td>\n",
       "      <td>-6.133252</td>\n",
       "      <td>5.726628</td>\n",
       "      <td>-45.872483</td>\n",
       "      <td>28.380931</td>\n",
       "      <td>-30.701357</td>\n",
       "      <td>20.523078</td>\n",
       "      <td>-3.909566</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>17.781660</td>\n",
       "      <td>-19.684223</td>\n",
       "      <td>48.454667</td>\n",
       "      <td>-18.190603</td>\n",
       "      <td>31.816934</td>\n",
       "      <td>8.748907</td>\n",
       "      <td>-21.019876</td>\n",
       "      <td>-1.103030</td>\n",
       "      <td>84.474686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I_Coil_S_1   I_Coil_S_2   I_Coil_S_3   I_Coil_S_4  I_Coil_S_5   I_Coil_S_6  \\\n",
       "0  838.911750   759.710510   151.419436  1615.056972  743.575343   391.038655   \n",
       "1   63.159728  1145.927954  1657.822801   304.390164  494.859837  1807.131972   \n",
       "2  604.895390  1687.818115  1012.687243  1502.671404  405.011494  1454.313326   \n",
       "3   17.840346  1759.438076  1574.016330   212.658270  330.123381  1857.333290   \n",
       "4  309.189519  1211.884724  1241.877155  1765.598706  958.032189   180.943129   \n",
       "\n",
       "    I_Coil_S_7   I_Coil_S_8   I_Coil_S_9  I_Coil_S_10  I_Coil_S_11  \\\n",
       "0  1261.606568   242.427231  1517.168814  1235.880686  1136.968086   \n",
       "1  1049.181833    94.704052   489.101852   426.085510   358.871208   \n",
       "2   589.616445  1840.587726    21.227596   353.216915  1263.009765   \n",
       "3   970.880979   224.690144  1995.096232  1716.554497   938.142312   \n",
       "4  1683.015986  1804.044797  1496.436842  1253.418474  1899.860847   \n",
       "\n",
       "   I_Coil_S_12  I_Coil_S_13  I_Coil_S_14  I_Coil_S_15  I_Coil_S_16  \\\n",
       "0  1644.552590  1299.043478   373.753114  1154.363677   968.558844   \n",
       "1  1578.618173   314.545535   612.220245   636.828373   622.404727   \n",
       "2  1345.094191  1366.001321   110.808211   729.066266  1374.909432   \n",
       "3   231.825997   574.401833   312.836168  1135.919141  1026.209542   \n",
       "4  1739.772124   860.744173     9.266228   829.254146   643.718123   \n",
       "\n",
       "   I_Coil_S_17  I_Coil_S_18  I_Coil_S_19  I_Coil_S_20  I_Coil_S_21  \\\n",
       "0   475.046566  1728.383799   695.624587  1451.133024   805.648549   \n",
       "1   404.759696  1805.421913  1690.866852  1461.239642   280.030105   \n",
       "2   153.261000   279.744488   658.661727  1519.840001  1756.416608   \n",
       "3  1396.933967  1093.977710  1367.545965  1917.831175   823.392415   \n",
       "4   404.240796  1258.558023  1777.273983   630.647459  1237.191367   \n",
       "\n",
       "   I_Coil_S_22  I_Coil_S_23  I_Coil_S_24  I_Coil_S_25  I_Coil_S_26  \\\n",
       "0  1142.269616   200.665408  1902.587556   601.935652    40.713244   \n",
       "1  1460.276274     5.973251   268.499457   870.218774   570.007014   \n",
       "2  1286.093196   501.047096  1929.647805   974.581579   129.650555   \n",
       "3   595.425860  1878.078629  1205.817297   597.432528   858.841403   \n",
       "4   459.165193   803.252614   937.639814  1289.839030   338.787254   \n",
       "\n",
       "   I_Coil_S_27  I_Coil_S_28  I_Coil_S_29  I_Coil_S_30   T_R_Core  T_R_Core_2  \\\n",
       "0  1532.422884  1856.700587   418.592063   955.759736  15.479226  -42.847403   \n",
       "1  1128.917385   703.853609   597.595272  1904.930449  11.229471  -12.536256   \n",
       "2  1607.304410   820.807789  1824.520892   473.856855  17.637504  -31.529522   \n",
       "3   343.724064   882.827033   445.642094  1678.188694  12.994437   -6.987048   \n",
       "4    61.456967  1785.606285  1092.452883   835.650610  15.827835  -28.320735   \n",
       "\n",
       "   T_R_Core_3  T_R_Core_4  T_R_Core_5  T_R_Core_6  T_R_Core_7  T_R_Core_8  \\\n",
       "0    6.064716  -12.895680   18.252286  -29.389699   11.222207  -26.003880   \n",
       "1   30.446560 -103.580160   20.265228   17.454621   19.543563  -38.937267   \n",
       "2   15.031434  -49.240416   15.424546    5.433440   13.185292   38.785119   \n",
       "3   24.382430  -80.895173   16.929088   35.475627    7.852790  -11.329015   \n",
       "4   36.028130  -32.938019   21.500328  -36.722931  -10.237192   39.495440   \n",
       "\n",
       "   T_R_Core_9  T_R_Core_10  T_R_Core_11  T_R_Core_12  T_R_Core_13  \\\n",
       "0  -21.294832    31.174374   -29.326844   112.638421   -24.577963   \n",
       "1  -10.905801    13.979060    -8.572148   112.500900    -8.759866   \n",
       "2  -19.140526    20.559278    -7.332849    97.164002   -16.685405   \n",
       "3  -17.989747    53.259204   -40.250328    25.070360    -0.386462   \n",
       "4  -44.268432    59.057567   -10.266856    76.100659   -17.603028   \n",
       "\n",
       "   T_R_Core_14  T_R_Core_15  T_R_Core_16  T_R_Core_17  T_R_Core_18  \\\n",
       "0    24.606552     4.854151   -57.440308    27.289150  -117.839598   \n",
       "1    25.504916     0.290484   -40.982595    41.326342  -100.186679   \n",
       "2     5.809139     6.244711   -75.382638    -5.592654   -13.735950   \n",
       "3     7.051670    10.609738   -65.145659    22.312188   -42.883271   \n",
       "4    -6.133252     5.726628   -45.872483    28.380931   -30.701357   \n",
       "\n",
       "   T_R_Core_19  T_R_Core_20  T_R_Core_21  T_R_Core_22  T_R_Core_23  \\\n",
       "0    37.453612   -47.446869    17.398821   -26.851500   -28.688864   \n",
       "1    26.732960   -66.229009     9.483419   -44.946565    -8.622409   \n",
       "2    50.292172   -13.282855    17.478178   -22.011852   -25.213906   \n",
       "3    46.302679   -69.812219     4.260714    57.851876   -41.122330   \n",
       "4    20.523078    -3.909566     0.900474    17.781660   -19.684223   \n",
       "\n",
       "   T_R_Core_24  T_R_Core_25  T_R_Core_26  T_R_Core_27  T_R_Core_28  \\\n",
       "0   -13.777332   -11.467442   122.742396   -14.451273    10.036495   \n",
       "1    27.807482   -15.351617    82.259023   -10.616755    31.961057   \n",
       "2     8.814699   -19.264357   130.770247   -13.454053    36.582125   \n",
       "3    13.443905   -17.304365    29.278734    -2.543550     5.425467   \n",
       "4    48.454667   -18.190603    31.816934     8.748907   -21.019876   \n",
       "\n",
       "   Rotor_posn  Net_Torque  \n",
       "0   -1.200000  -65.087081  \n",
       "1   -1.175758    0.557958  \n",
       "2   -1.151515  167.344904  \n",
       "3   -1.127273  -24.148261  \n",
       "4   -1.103030   84.474686  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(current_dir.absolute() / 'concatDataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c2952-8876-4fbc-992b-0481e5e0c114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22400, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b00fb0-3057-4143-8ecc-b8cef693d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename({'T_R_Core' : 'T_R_Core_1'}, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8590df8-0ec5-4bc7-badd-76dedab14fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_R_Core_1</th>\n",
       "      <th>I_Coil_S_1</th>\n",
       "      <th>Rotor_posn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>2.240000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.209673</td>\n",
       "      <td>996.029242</td>\n",
       "      <td>3.092764e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>48.230066</td>\n",
       "      <td>578.535337</td>\n",
       "      <td>6.997991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-110.847693</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>-1.200000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.347180</td>\n",
       "      <td>494.145012</td>\n",
       "      <td>-6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.223036</td>\n",
       "      <td>992.259122</td>\n",
       "      <td>1.006140e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.158135</td>\n",
       "      <td>1496.497232</td>\n",
       "      <td>6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.900608</td>\n",
       "      <td>1999.980027</td>\n",
       "      <td>1.200000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T_R_Core_1    I_Coil_S_1    Rotor_posn\n",
       "count  22400.000000  22400.000000  2.240000e+04\n",
       "mean      55.209673    996.029242  3.092764e-17\n",
       "std       48.230066    578.535337  6.997991e-01\n",
       "min     -110.847693      0.013550 -1.200000e+00\n",
       "25%       25.347180    494.145012 -6.000000e-01\n",
       "50%       50.223036    992.259122  1.006140e-16\n",
       "75%       82.158135   1496.497232  6.000000e-01\n",
       "max      243.900608   1999.980027  1.200000e+00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['T_R_Core_1', 'I_Coil_S_1', 'Rotor_posn']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d3e5f-f991-4fe0-b0fc-13064020822f",
   "metadata": {},
   "source": [
    "# Data prep for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110f2fa-cab2-4bc9-9d00-bf129bdf2ff3",
   "metadata": {},
   "source": [
    "## Supporting dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3c20e8-a587-4b3f-974e-11cfd462a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stator_pole_position = {f'S_{sp+1}' : round(36/30 * sp, 1) for sp in range(30)}\n",
    "# stator_pole_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be532d6c-d768-4ab7-98de-c299cd7b7374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R_1': 0.0,\n",
       " 'R_2': 1.29,\n",
       " 'R_3': 2.57,\n",
       " 'R_4': 3.86,\n",
       " 'R_5': 5.14,\n",
       " 'R_6': 6.43,\n",
       " 'R_7': 7.71,\n",
       " 'R_8': 9.0,\n",
       " 'R_9': 10.29,\n",
       " 'R_10': 11.57,\n",
       " 'R_11': 12.86,\n",
       " 'R_12': 14.14,\n",
       " 'R_13': 15.43,\n",
       " 'R_14': 16.71,\n",
       " 'R_15': 18.0,\n",
       " 'R_16': 19.29,\n",
       " 'R_17': 20.57,\n",
       " 'R_18': 21.86,\n",
       " 'R_19': 23.14,\n",
       " 'R_20': 24.43,\n",
       " 'R_21': 25.71,\n",
       " 'R_22': 27.0,\n",
       " 'R_23': 28.29,\n",
       " 'R_24': 29.57,\n",
       " 'R_25': 30.86,\n",
       " 'R_26': 32.14,\n",
       " 'R_27': 33.43,\n",
       " 'R_28': 34.71}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotor_pole_position = {f'R_{rp+1}' : round(36/28 * rp, 2) for rp in range(28)}\n",
    "rotor_pole_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca64fb67-f2ce-4c30-93d6-1d6133bb8417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_key(stator_dict, target_value):\n",
    "    closest_key = min(stator_dict, key=lambda x: abs(stator_dict[x] - target_value))\n",
    "    return closest_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f743aa3b-96db-4895-908a-af0878ca92b8",
   "metadata": {},
   "source": [
    "## Finding clostest stator rotor pole pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7243532-efe3-4498-9c85-16ce844e9829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rotor: 1 at posn: 0.0,           closest stator: S_1 at : 0.0\n",
      "For rotor: 2 at posn: 1.29,           closest stator: S_2 at : 1.2\n",
      "For rotor: 3 at posn: 2.57,           closest stator: S_3 at : 2.4\n",
      "For rotor: 4 at posn: 3.86,           closest stator: S_4 at : 3.6\n",
      "For rotor: 5 at posn: 5.14,           closest stator: S_5 at : 4.8\n",
      "For rotor: 6 at posn: 6.43,           closest stator: S_6 at : 6.0\n",
      "For rotor: 7 at posn: 7.71,           closest stator: S_7 at : 7.2\n",
      "For rotor: 8 at posn: 9.0,           closest stator: S_8 at : 8.4\n",
      "For rotor: 9 at posn: 10.29,           closest stator: S_10 at : 10.8\n",
      "For rotor: 10 at posn: 11.57,           closest stator: S_11 at : 12.0\n",
      "For rotor: 11 at posn: 12.86,           closest stator: S_12 at : 13.2\n",
      "For rotor: 12 at posn: 14.14,           closest stator: S_13 at : 14.4\n",
      "For rotor: 13 at posn: 15.43,           closest stator: S_14 at : 15.6\n",
      "For rotor: 14 at posn: 16.71,           closest stator: S_15 at : 16.8\n",
      "For rotor: 15 at posn: 18.0,           closest stator: S_16 at : 18.0\n",
      "For rotor: 16 at posn: 19.29,           closest stator: S_17 at : 19.2\n",
      "For rotor: 17 at posn: 20.57,           closest stator: S_18 at : 20.4\n",
      "For rotor: 18 at posn: 21.86,           closest stator: S_19 at : 21.6\n",
      "For rotor: 19 at posn: 23.14,           closest stator: S_20 at : 22.8\n",
      "For rotor: 20 at posn: 24.43,           closest stator: S_21 at : 24.0\n",
      "For rotor: 21 at posn: 25.71,           closest stator: S_22 at : 25.2\n",
      "For rotor: 22 at posn: 27.0,           closest stator: S_23 at : 26.4\n",
      "For rotor: 23 at posn: 28.29,           closest stator: S_25 at : 28.8\n",
      "For rotor: 24 at posn: 29.57,           closest stator: S_26 at : 30.0\n",
      "For rotor: 25 at posn: 30.86,           closest stator: S_27 at : 31.2\n",
      "For rotor: 26 at posn: 32.14,           closest stator: S_28 at : 32.4\n",
      "For rotor: 27 at posn: 33.43,           closest stator: S_29 at : 33.6\n",
      "For rotor: 28 at posn: 34.71,           closest stator: S_30 at : 34.8\n"
     ]
    }
   ],
   "source": [
    "rotor_stator_pairs = {}\n",
    "for rotor in rotor_pole_position:\n",
    "    rotor_id = int(rotor[2:])\n",
    "    target_value = rotor_pole_position[rotor]\n",
    "    target_stator = find_closest_key(stator_pole_position, target_value)\n",
    "    print(f'For rotor: {rotor_id} at posn: {target_value}, \\\n",
    "          closest stator: {target_stator} at : {stator_pole_position[target_stator]}')\n",
    "    rotor_stator_pairs[rotor] = target_stator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3a3f36-36b7-4a1d-8971-354f6704757d",
   "metadata": {},
   "source": [
    "Stator# 9 and 24 skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13effcb3-882a-4ece-9d00-6ae6f1a6269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R_1': 'S_1',\n",
       " 'R_2': 'S_2',\n",
       " 'R_3': 'S_3',\n",
       " 'R_4': 'S_4',\n",
       " 'R_5': 'S_5',\n",
       " 'R_6': 'S_6',\n",
       " 'R_7': 'S_7',\n",
       " 'R_8': 'S_8',\n",
       " 'R_9': 'S_10',\n",
       " 'R_10': 'S_11',\n",
       " 'R_11': 'S_12',\n",
       " 'R_12': 'S_13',\n",
       " 'R_13': 'S_14',\n",
       " 'R_14': 'S_15',\n",
       " 'R_15': 'S_16',\n",
       " 'R_16': 'S_17',\n",
       " 'R_17': 'S_18',\n",
       " 'R_18': 'S_19',\n",
       " 'R_19': 'S_20',\n",
       " 'R_20': 'S_21',\n",
       " 'R_21': 'S_22',\n",
       " 'R_22': 'S_23',\n",
       " 'R_23': 'S_25',\n",
       " 'R_24': 'S_26',\n",
       " 'R_25': 'S_27',\n",
       " 'R_26': 'S_28',\n",
       " 'R_27': 'S_29',\n",
       " 'R_28': 'S_30'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotor_stator_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0da106ac-ae6f-4c4f-bb5f-a7cf02f70712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_Coil_S_1</th>\n",
       "      <th>I_Coil_S_2</th>\n",
       "      <th>I_Coil_S_3</th>\n",
       "      <th>I_Coil_S_4</th>\n",
       "      <th>I_Coil_S_5</th>\n",
       "      <th>I_Coil_S_6</th>\n",
       "      <th>I_Coil_S_7</th>\n",
       "      <th>I_Coil_S_8</th>\n",
       "      <th>I_Coil_S_9</th>\n",
       "      <th>I_Coil_S_10</th>\n",
       "      <th>I_Coil_S_11</th>\n",
       "      <th>I_Coil_S_12</th>\n",
       "      <th>I_Coil_S_13</th>\n",
       "      <th>I_Coil_S_14</th>\n",
       "      <th>I_Coil_S_15</th>\n",
       "      <th>I_Coil_S_16</th>\n",
       "      <th>I_Coil_S_17</th>\n",
       "      <th>I_Coil_S_18</th>\n",
       "      <th>I_Coil_S_19</th>\n",
       "      <th>I_Coil_S_20</th>\n",
       "      <th>I_Coil_S_21</th>\n",
       "      <th>I_Coil_S_22</th>\n",
       "      <th>I_Coil_S_23</th>\n",
       "      <th>I_Coil_S_24</th>\n",
       "      <th>I_Coil_S_25</th>\n",
       "      <th>I_Coil_S_26</th>\n",
       "      <th>I_Coil_S_27</th>\n",
       "      <th>I_Coil_S_28</th>\n",
       "      <th>I_Coil_S_29</th>\n",
       "      <th>I_Coil_S_30</th>\n",
       "      <th>T_R_Core_1</th>\n",
       "      <th>T_R_Core_2</th>\n",
       "      <th>T_R_Core_3</th>\n",
       "      <th>T_R_Core_4</th>\n",
       "      <th>T_R_Core_5</th>\n",
       "      <th>T_R_Core_6</th>\n",
       "      <th>T_R_Core_7</th>\n",
       "      <th>T_R_Core_8</th>\n",
       "      <th>T_R_Core_9</th>\n",
       "      <th>T_R_Core_10</th>\n",
       "      <th>T_R_Core_11</th>\n",
       "      <th>T_R_Core_12</th>\n",
       "      <th>T_R_Core_13</th>\n",
       "      <th>T_R_Core_14</th>\n",
       "      <th>T_R_Core_15</th>\n",
       "      <th>T_R_Core_16</th>\n",
       "      <th>T_R_Core_17</th>\n",
       "      <th>T_R_Core_18</th>\n",
       "      <th>T_R_Core_19</th>\n",
       "      <th>T_R_Core_20</th>\n",
       "      <th>T_R_Core_21</th>\n",
       "      <th>T_R_Core_22</th>\n",
       "      <th>T_R_Core_23</th>\n",
       "      <th>T_R_Core_24</th>\n",
       "      <th>T_R_Core_25</th>\n",
       "      <th>T_R_Core_26</th>\n",
       "      <th>T_R_Core_27</th>\n",
       "      <th>T_R_Core_28</th>\n",
       "      <th>Rotor_posn</th>\n",
       "      <th>Net_Torque</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>838.911750</td>\n",
       "      <td>759.710510</td>\n",
       "      <td>151.419436</td>\n",
       "      <td>1615.056972</td>\n",
       "      <td>743.575343</td>\n",
       "      <td>391.038655</td>\n",
       "      <td>1261.606568</td>\n",
       "      <td>242.427231</td>\n",
       "      <td>1517.168814</td>\n",
       "      <td>1235.880686</td>\n",
       "      <td>1136.968086</td>\n",
       "      <td>1644.552590</td>\n",
       "      <td>1299.043478</td>\n",
       "      <td>373.753114</td>\n",
       "      <td>1154.363677</td>\n",
       "      <td>968.558844</td>\n",
       "      <td>475.046566</td>\n",
       "      <td>1728.383799</td>\n",
       "      <td>695.624587</td>\n",
       "      <td>1451.133024</td>\n",
       "      <td>805.648549</td>\n",
       "      <td>1142.269616</td>\n",
       "      <td>200.665408</td>\n",
       "      <td>1902.587556</td>\n",
       "      <td>601.935652</td>\n",
       "      <td>40.713244</td>\n",
       "      <td>1532.422884</td>\n",
       "      <td>1856.700587</td>\n",
       "      <td>418.592063</td>\n",
       "      <td>955.759736</td>\n",
       "      <td>15.479226</td>\n",
       "      <td>-42.847403</td>\n",
       "      <td>6.064716</td>\n",
       "      <td>-12.89568</td>\n",
       "      <td>18.252286</td>\n",
       "      <td>-29.389699</td>\n",
       "      <td>11.222207</td>\n",
       "      <td>-26.003880</td>\n",
       "      <td>-21.294832</td>\n",
       "      <td>31.174374</td>\n",
       "      <td>-29.326844</td>\n",
       "      <td>112.638421</td>\n",
       "      <td>-24.577963</td>\n",
       "      <td>24.606552</td>\n",
       "      <td>4.854151</td>\n",
       "      <td>-57.440308</td>\n",
       "      <td>27.289150</td>\n",
       "      <td>-117.839598</td>\n",
       "      <td>37.453612</td>\n",
       "      <td>-47.446869</td>\n",
       "      <td>17.398821</td>\n",
       "      <td>-26.851500</td>\n",
       "      <td>-28.688864</td>\n",
       "      <td>-13.777332</td>\n",
       "      <td>-11.467442</td>\n",
       "      <td>122.742396</td>\n",
       "      <td>-14.451273</td>\n",
       "      <td>10.036495</td>\n",
       "      <td>-1.200000</td>\n",
       "      <td>-65.087081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63.159728</td>\n",
       "      <td>1145.927954</td>\n",
       "      <td>1657.822801</td>\n",
       "      <td>304.390164</td>\n",
       "      <td>494.859837</td>\n",
       "      <td>1807.131972</td>\n",
       "      <td>1049.181833</td>\n",
       "      <td>94.704052</td>\n",
       "      <td>489.101852</td>\n",
       "      <td>426.085510</td>\n",
       "      <td>358.871208</td>\n",
       "      <td>1578.618173</td>\n",
       "      <td>314.545535</td>\n",
       "      <td>612.220245</td>\n",
       "      <td>636.828373</td>\n",
       "      <td>622.404727</td>\n",
       "      <td>404.759696</td>\n",
       "      <td>1805.421913</td>\n",
       "      <td>1690.866852</td>\n",
       "      <td>1461.239642</td>\n",
       "      <td>280.030105</td>\n",
       "      <td>1460.276274</td>\n",
       "      <td>5.973251</td>\n",
       "      <td>268.499457</td>\n",
       "      <td>870.218774</td>\n",
       "      <td>570.007014</td>\n",
       "      <td>1128.917385</td>\n",
       "      <td>703.853609</td>\n",
       "      <td>597.595272</td>\n",
       "      <td>1904.930449</td>\n",
       "      <td>11.229471</td>\n",
       "      <td>-12.536256</td>\n",
       "      <td>30.446560</td>\n",
       "      <td>-103.58016</td>\n",
       "      <td>20.265228</td>\n",
       "      <td>17.454621</td>\n",
       "      <td>19.543563</td>\n",
       "      <td>-38.937267</td>\n",
       "      <td>-10.905801</td>\n",
       "      <td>13.979060</td>\n",
       "      <td>-8.572148</td>\n",
       "      <td>112.500900</td>\n",
       "      <td>-8.759866</td>\n",
       "      <td>25.504916</td>\n",
       "      <td>0.290484</td>\n",
       "      <td>-40.982595</td>\n",
       "      <td>41.326342</td>\n",
       "      <td>-100.186679</td>\n",
       "      <td>26.732960</td>\n",
       "      <td>-66.229009</td>\n",
       "      <td>9.483419</td>\n",
       "      <td>-44.946565</td>\n",
       "      <td>-8.622409</td>\n",
       "      <td>27.807482</td>\n",
       "      <td>-15.351617</td>\n",
       "      <td>82.259023</td>\n",
       "      <td>-10.616755</td>\n",
       "      <td>31.961057</td>\n",
       "      <td>-1.175758</td>\n",
       "      <td>0.557958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   I_Coil_S_1   I_Coil_S_2   I_Coil_S_3   I_Coil_S_4  I_Coil_S_5   I_Coil_S_6  \\\n",
       "0  838.911750   759.710510   151.419436  1615.056972  743.575343   391.038655   \n",
       "1   63.159728  1145.927954  1657.822801   304.390164  494.859837  1807.131972   \n",
       "\n",
       "    I_Coil_S_7  I_Coil_S_8   I_Coil_S_9  I_Coil_S_10  I_Coil_S_11  \\\n",
       "0  1261.606568  242.427231  1517.168814  1235.880686  1136.968086   \n",
       "1  1049.181833   94.704052   489.101852   426.085510   358.871208   \n",
       "\n",
       "   I_Coil_S_12  I_Coil_S_13  I_Coil_S_14  I_Coil_S_15  I_Coil_S_16  \\\n",
       "0  1644.552590  1299.043478   373.753114  1154.363677   968.558844   \n",
       "1  1578.618173   314.545535   612.220245   636.828373   622.404727   \n",
       "\n",
       "   I_Coil_S_17  I_Coil_S_18  I_Coil_S_19  I_Coil_S_20  I_Coil_S_21  \\\n",
       "0   475.046566  1728.383799   695.624587  1451.133024   805.648549   \n",
       "1   404.759696  1805.421913  1690.866852  1461.239642   280.030105   \n",
       "\n",
       "   I_Coil_S_22  I_Coil_S_23  I_Coil_S_24  I_Coil_S_25  I_Coil_S_26  \\\n",
       "0  1142.269616   200.665408  1902.587556   601.935652    40.713244   \n",
       "1  1460.276274     5.973251   268.499457   870.218774   570.007014   \n",
       "\n",
       "   I_Coil_S_27  I_Coil_S_28  I_Coil_S_29  I_Coil_S_30  T_R_Core_1  T_R_Core_2  \\\n",
       "0  1532.422884  1856.700587   418.592063   955.759736   15.479226  -42.847403   \n",
       "1  1128.917385   703.853609   597.595272  1904.930449   11.229471  -12.536256   \n",
       "\n",
       "   T_R_Core_3  T_R_Core_4  T_R_Core_5  T_R_Core_6  T_R_Core_7  T_R_Core_8  \\\n",
       "0    6.064716   -12.89568   18.252286  -29.389699   11.222207  -26.003880   \n",
       "1   30.446560  -103.58016   20.265228   17.454621   19.543563  -38.937267   \n",
       "\n",
       "   T_R_Core_9  T_R_Core_10  T_R_Core_11  T_R_Core_12  T_R_Core_13  \\\n",
       "0  -21.294832    31.174374   -29.326844   112.638421   -24.577963   \n",
       "1  -10.905801    13.979060    -8.572148   112.500900    -8.759866   \n",
       "\n",
       "   T_R_Core_14  T_R_Core_15  T_R_Core_16  T_R_Core_17  T_R_Core_18  \\\n",
       "0    24.606552     4.854151   -57.440308    27.289150  -117.839598   \n",
       "1    25.504916     0.290484   -40.982595    41.326342  -100.186679   \n",
       "\n",
       "   T_R_Core_19  T_R_Core_20  T_R_Core_21  T_R_Core_22  T_R_Core_23  \\\n",
       "0    37.453612   -47.446869    17.398821   -26.851500   -28.688864   \n",
       "1    26.732960   -66.229009     9.483419   -44.946565    -8.622409   \n",
       "\n",
       "   T_R_Core_24  T_R_Core_25  T_R_Core_26  T_R_Core_27  T_R_Core_28  \\\n",
       "0   -13.777332   -11.467442   122.742396   -14.451273    10.036495   \n",
       "1    27.807482   -15.351617    82.259023   -10.616755    31.961057   \n",
       "\n",
       "   Rotor_posn  Net_Torque  \n",
       "0   -1.200000  -65.087081  \n",
       "1   -1.175758    0.557958  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e8247-3d29-48ba-99fe-3ed3f2bd281e",
   "metadata": {},
   "source": [
    "## Generating dicts of dataframes (```data_ML_all```) fopr ML training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6448281c-9944-4d06-b9ce-c0f7b37edc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rotor: R_3...Min: -1.37, Max: 1.03, Range:  2.40,         Torque: 125.46, Shape: 22400\n",
      "For rotor: R_4...Min: -1.46, Max: 0.94, Range:  2.40,         Torque: 316.17, Shape: 22400\n",
      "For rotor: R_5...Min: -1.54, Max: 0.86, Range:  2.40,         Torque: 121.28, Shape: 22400\n",
      "For rotor: R_6...Min: -1.63, Max: 0.77, Range:  2.40,         Torque: 309.51, Shape: 22400\n",
      "For rotor: R_7...Min: -1.71, Max: 0.69, Range:  2.40,         Torque: 122.71, Shape: 22400\n",
      "For rotor: R_8...Min: -1.80, Max: 0.60, Range:  2.40,         Torque: 296.58, Shape: 22400\n",
      "For rotor: R_9...Min: -0.69, Max: 1.71, Range:  2.40,         Torque: 126.50, Shape: 22400\n",
      "For rotor: R_10...Min: -0.77, Max: 1.63, Range:  2.40,         Torque: 310.07, Shape: 22400\n",
      "For rotor: R_11...Min: -0.86, Max: 1.54, Range:  2.40,         Torque: 119.68, Shape: 22400\n",
      "For rotor: R_12...Min: -0.94, Max: 1.46, Range:  2.40,         Torque: 312.41, Shape: 22400\n",
      "For rotor: R_13...Min: -1.03, Max: 1.37, Range:  2.40,         Torque: 128.19, Shape: 22400\n",
      "For rotor: R_14...Min: -1.11, Max: 1.29, Range:  2.40,         Torque: 301.97, Shape: 22400\n",
      "For rotor: R_15...Min: -1.20, Max: 1.20, Range:  2.40,         Torque: 124.93, Shape: 22400\n",
      "For rotor: R_16...Min: -1.29, Max: 1.11, Range:  2.40,         Torque: 303.65, Shape: 22400\n",
      "For rotor: R_17...Min: -1.37, Max: 1.03, Range:  2.40,         Torque: 121.41, Shape: 22400\n",
      "For rotor: R_18...Min: -1.46, Max: 0.94, Range:  2.40,         Torque: 305.66, Shape: 22400\n",
      "For rotor: R_19...Min: -1.54, Max: 0.86, Range:  2.40,         Torque: 121.33, Shape: 22400\n",
      "For rotor: R_20...Min: -1.63, Max: 0.77, Range:  2.40,         Torque: 308.18, Shape: 22400\n",
      "For rotor: R_21...Min: -1.71, Max: 0.69, Range:  2.40,         Torque: 120.56, Shape: 22400\n",
      "For rotor: R_22...Min: -1.80, Max: 0.60, Range:  2.40,         Torque: 312.36, Shape: 22400\n",
      "For rotor: R_23...Min: -0.69, Max: 1.71, Range:  2.40,         Torque: 120.51, Shape: 22400\n",
      "For rotor: R_24...Min: -0.77, Max: 1.63, Range:  2.40,         Torque: 308.29, Shape: 22400\n",
      "For rotor: R_25...Min: -0.86, Max: 1.54, Range:  2.40,         Torque: 117.77, Shape: 22400\n"
     ]
    }
   ],
   "source": [
    "data_ML_all = {}\n",
    "for rotor in rotor_pole_position:\n",
    "    rotor_id = int(rotor[2:])\n",
    "    data_ML = pd.DataFrame(columns = ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D', 'torque_rotor'])\n",
    "    if rotor_id > 2 and rotor_id < 28- 2:\n",
    "        print(f'For rotor: {rotor}', end='...')\n",
    "        stator_id = int(rotor_stator_pairs[rotor][2:])\n",
    "        data_ML['rotor_posn'] = stator_pole_position[f'S_{stator_id}'] - (data['Rotor_posn'] + rotor_pole_position[rotor])\n",
    "        data_ML['stator_exc_0'] = data['I_Coil_' + rotor_stator_pairs[rotor]]\n",
    "        data_ML['stator_exc_U'] = data[f'I_Coil_S_{stator_id + 1}']\n",
    "        data_ML['stator_exc_D'] = data[f'I_Coil_S_{stator_id - 1}']\n",
    "        data_ML['torque_rotor'] = data[f'T_R_Core_{rotor_id}']\n",
    "        print(f\"Min: {data_ML['rotor_posn'].min():.2f}, Max: {data_ML['rotor_posn'].max():.2f}, Range: {data_ML['rotor_posn'].max() - data_ML['rotor_posn'].min(): .2f}, \\\n",
    "        Torque: {data_ML['torque_rotor'].max() - data_ML['torque_rotor'].min():.2f}, Shape: {data_ML.shape[0]}\")\n",
    "        data_ML_all[rotor] = data_ML\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee786d-10d1-4dc4-88eb-ada3c3539dd7",
   "metadata": {},
   "source": [
    "* Every alternate rotor pole torque range is 120Nm. \n",
    "* This should be due to using dataset with only positive excitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edefbdeb-33f1-4052-8c25-4e3a7f75e071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotor_posn</th>\n",
       "      <th>stator_exc_0</th>\n",
       "      <th>stator_exc_U</th>\n",
       "      <th>stator_exc_D</th>\n",
       "      <th>torque_rotor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.170000</td>\n",
       "      <td>996.900911</td>\n",
       "      <td>1003.020502</td>\n",
       "      <td>1002.405288</td>\n",
       "      <td>-1.167778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.699799</td>\n",
       "      <td>577.604178</td>\n",
       "      <td>575.561780</td>\n",
       "      <td>576.696840</td>\n",
       "      <td>20.780160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.370000</td>\n",
       "      <td>0.103686</td>\n",
       "      <td>0.111777</td>\n",
       "      <td>0.097202</td>\n",
       "      <td>-62.869201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.770000</td>\n",
       "      <td>494.269513</td>\n",
       "      <td>500.168919</td>\n",
       "      <td>508.436744</td>\n",
       "      <td>-15.648767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.170000</td>\n",
       "      <td>1003.104630</td>\n",
       "      <td>996.666789</td>\n",
       "      <td>999.583852</td>\n",
       "      <td>-1.775934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.430000</td>\n",
       "      <td>1490.050507</td>\n",
       "      <td>1504.467747</td>\n",
       "      <td>1501.528661</td>\n",
       "      <td>13.153638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.030000</td>\n",
       "      <td>1999.957406</td>\n",
       "      <td>1999.987138</td>\n",
       "      <td>1999.988031</td>\n",
       "      <td>62.593093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rotor_posn  stator_exc_0  stator_exc_U  stator_exc_D  torque_rotor\n",
       "count  22400.000000  22400.000000  22400.000000  22400.000000  22400.000000\n",
       "mean      -0.170000    996.900911   1003.020502   1002.405288     -1.167778\n",
       "std        0.699799    577.604178    575.561780    576.696840     20.780160\n",
       "min       -1.370000      0.103686      0.111777      0.097202    -62.869201\n",
       "25%       -0.770000    494.269513    500.168919    508.436744    -15.648767\n",
       "50%       -0.170000   1003.104630    996.666789    999.583852     -1.775934\n",
       "75%        0.430000   1490.050507   1504.467747   1501.528661     13.153638\n",
       "max        1.030000   1999.957406   1999.987138   1999.988031     62.593093"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ML_all['R_3'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5b13756-027a-4e4d-85c5-194e84b55628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(current_dir.absolute() / 'data_ML_all.pickle', 'wb') as file:\n",
    "    pickle.dump(data_ML_all, file)\n",
    "    \n",
    "    \n",
    "# for reading    \n",
    "# with open('data_ML_all.pickle', 'rb') as file:\n",
    "#     data_ML_all = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee524b-01d9-4b49-90b1-ff01549831fb",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff98be2-e7fb-465f-868b-c2c619c41c6a",
   "metadata": {},
   "source": [
    "## H2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24d598e4-113e-4c3f-b439-8f0ad4c74133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.44.0.3\n",
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM 18.9 (build 11.0.12+8-LTS-237, mixed mode)\n",
      "  Starting server from C:\\Users\\akhan147\\Anaconda3\\envs\\tf-cpu11\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\akhan147\\AppData\\Local\\Temp\\tmpk7_85iww\n",
      "  JVM stdout: C:\\Users\\akhan147\\AppData\\Local\\Temp\\tmpk7_85iww\\h2o_akhan147_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\akhan147\\AppData\\Local\\Temp\\tmpk7_85iww\\h2o_akhan147_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>04 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 13 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_akhan147_p44w3q</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>24 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.8 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O_cluster_uptime:         04 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    2 months and 13 days\n",
       "H2O_cluster_name:           H2O_from_python_akhan147_p44w3q\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    24 Gb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.8 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "print(h2o.__version__)\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init(max_mem_size='24G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d0152-a059-4f8e-b9c0-018e13edd7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rotor in rotor_pole_position:\n",
    "    rotor_id = int(rotor[2:])\n",
    "    if rotor_id > 2 and rotor_id < 28- 2:\n",
    "        rotor_data = data_ML_all[rotor]\n",
    "        X_features = rotor_data.drop('torque_rotor', axis=1)\n",
    "        target = rotor_data['torque_rotor']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_features, target, test_size=0.2, random_state=42)\n",
    "        x = X_features.columns\n",
    "        y = 'torque_rotor'\n",
    "        \n",
    "        train_data = pd.concat([X_train, y_train], axis=1)\n",
    "        test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "        train = h2o.H2OFrame(train_data)\n",
    "        test = h2o.H2OFrame(test_data)\n",
    "        \n",
    "        x = list(x)\n",
    "        aml = H2OAutoML(max_runtime_secs = 180,\n",
    "                max_runtime_secs_per_model=60,\n",
    "                seed = 1,\n",
    "                project_name = f\"{rotor}\",\n",
    "                stopping_metric=\"RMSE\",\n",
    "                sort_metric=\"RMSE\")\n",
    "        aml.train(x = x, y = y, training_frame = train)\n",
    "        \n",
    "        performance = aml.leader.model_performance(test)\n",
    "\n",
    "        # Save performance metrics to a log file\n",
    "        with open(f\"{rotor}.log\", \"w\") as file:\n",
    "            file.write(str(performance))\n",
    "        \n",
    "        model_path = h2o.save_model(aml.leader, path=f'{rotor}', force=True)\n",
    "        print(rotor, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e7b8f-52ef-4673-9d2f-ac8ea28d9124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74bb7e6-1f4b-419e-9ba5-502339358e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88badf85-4072-4bd9-8688-60b4377fdca2",
   "metadata": {},
   "source": [
    "## AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "917abb36-1ee3-46e8-8720-6f8443b9b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4aef87-7f44-40a9-a283-d2c5f9476140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f60d6106-15c5-4113-8fdb-8113b86dda5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"agModels-R_3\"\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_3\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.02 GB / 31.93 GB (56.4%)\n",
      "Disk Space Avail:   11.28 GB / 100.00 GB (11.3%)\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (60.9456524621406, -62.8692014582248, -1.25548, 20.83046)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18446.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.92s of the 179.92s of remaining time.\n",
      "\t-22.6753\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.84s of the 179.84s of remaining time.\n",
      "\t-22.935\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.77s of the 179.77s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.42591\n",
      "[2000]\tvalid_set's rmse: 3.22141\n",
      "[3000]\tvalid_set's rmse: 3.20074\n",
      "[4000]\tvalid_set's rmse: 3.19998\n",
      "[5000]\tvalid_set's rmse: 3.19835\n",
      "[6000]\tvalid_set's rmse: 3.20433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.1946\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.42s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 174.98s of the 174.98s of remaining time.\n",
      "\t-3.1827\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 174.08s of the 174.08s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.19527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.4769\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.81s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 166.89s of the 166.89s of remaining time.\n",
      "\t-3.043\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 157.41s of the 157.41s of remaining time.\n",
      "\t-3.3157\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 154.55s of the 154.55s of remaining time.\n",
      "\t-5.4808\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.54s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 138.93s of the 138.93s of remaining time.\n",
      "\t-3.1886\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.64s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 138.22s of the 138.22s of remaining time.\n",
      "\t-3.6081\t = Validation score   (-root_mean_squared_error)\n",
      "\t68.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 70.14s of the 70.14s of remaining time.\n",
      "\t-3.2386\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.92s of the 68.76s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.615, 'XGBoost': 0.135, 'NeuralNetTorch': 0.125, 'LightGBMXT': 0.062, 'LightGBMLarge': 0.031, 'ExtraTreesMSE': 0.021, 'LightGBM': 0.01}\n",
      "\t-3.0099\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 111.63s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_3\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_4\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.08 GB / 31.93 GB (56.6%)\n",
      "Disk Space Avail:   10.46 GB / 100.00 GB (10.5%)\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (157.742666722722, -158.42249619034, -1.69666, 53.40937)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18516.40 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-58.1811\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-58.7945\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.69s of the 179.69s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.75593\n",
      "[2000]\tvalid_set's rmse: 6.09062\n",
      "[3000]\tvalid_set's rmse: 5.84495\n",
      "[4000]\tvalid_set's rmse: 5.72563\n",
      "[5000]\tvalid_set's rmse: 5.65111\n",
      "[6000]\tvalid_set's rmse: 5.60546\n",
      "[7000]\tvalid_set's rmse: 5.58446\n",
      "[8000]\tvalid_set's rmse: 5.57476\n",
      "[9000]\tvalid_set's rmse: 5.57706\n",
      "[10000]\tvalid_set's rmse: 5.58359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.5736\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.14s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 171.68s of the 171.68s of remaining time.\n",
      "\t-5.4317\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.45196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.77s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.78s of the 170.78s of remaining time.\n",
      "\t-6.0374\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.86s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.88s of the 163.88s of remaining time.\n",
      "\t-5.1462\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.79s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 154.02s of the 154.02s of remaining time.\n",
      "\t-5.6576\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 150.85s of the 150.85s of remaining time.\n",
      "\t-10.6716\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.55s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 135.16s of the 135.15s of remaining time.\n",
      "\t-5.5497\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 134.24s of the 134.24s of remaining time.\n",
      "\t-8.4021\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.94s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 105.22s of the 105.21s of remaining time.\n",
      "\t-5.5112\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 103.63s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.662, 'LightGBM': 0.117, 'ExtraTreesMSE': 0.078, 'LightGBMXT': 0.065, 'XGBoost': 0.039, 'LightGBMLarge': 0.039}\n",
      "\t-5.1078\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 76.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_4\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_5\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.09 GB / 31.93 GB (56.7%)\n",
      "Disk Space Avail:   10.45 GB / 100.00 GB (10.5%)\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (63.3026361476331, -55.7405553894954, 0.84137, 20.02294)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18525.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-22.0967\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.8s of the 179.79s of remaining time.\n",
      "\t-22.3211\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.69s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.8088\n",
      "[2000]\tvalid_set's rmse: 4.67874\n",
      "[3000]\tvalid_set's rmse: 4.66889\n",
      "[4000]\tvalid_set's rmse: 4.66916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.6599\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.42s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 175.96s of the 175.96s of remaining time.\n",
      "\t-4.6026\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 175.3s of the 175.3s of remaining time.\n",
      "\t-4.756\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.87s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 168.37s of the 168.37s of remaining time.\n",
      "\t-4.4839\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.85s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 161.45s of the 161.45s of remaining time.\n",
      "\t-4.6727\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 158.75s of the 158.75s of remaining time.\n",
      "\t-6.0537\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.96s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 142.64s of the 142.64s of remaining time.\n",
      "\t-4.6472\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 142.0s of the 142.0s of remaining time.\n",
      "\t-5.042\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.89s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 93.03s of the 93.02s of remaining time.\n",
      "\t-4.6432\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 91.64s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.544, 'NeuralNetTorch': 0.152, 'ExtraTreesMSE': 0.101, 'LightGBM': 0.076, 'LightGBMLarge': 0.063, 'XGBoost': 0.038, 'RandomForestMSE': 0.025}\n",
      "\t-4.438\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 88.84s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_5\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_6\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.06 GB / 31.93 GB (56.5%)\n",
      "Disk Space Avail:   10.40 GB / 100.00 GB (10.4%)\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (154.745646541629, -154.76002787909, -1.2194, 53.27081)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18491.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.92s of remaining time.\n",
      "\t-56.1852\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-56.5829\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.63685\n",
      "[2000]\tvalid_set's rmse: 6.1656\n",
      "[3000]\tvalid_set's rmse: 5.98972\n",
      "[4000]\tvalid_set's rmse: 5.89069\n",
      "[5000]\tvalid_set's rmse: 5.8495\n",
      "[6000]\tvalid_set's rmse: 5.82314\n",
      "[7000]\tvalid_set's rmse: 5.81316\n",
      "[8000]\tvalid_set's rmse: 5.80782\n",
      "[9000]\tvalid_set's rmse: 5.80946\n",
      "[10000]\tvalid_set's rmse: 5.80157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.8002\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.22s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 171.28s of the 171.28s of remaining time.\n",
      "\t-5.6184\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.55s of the 170.55s of remaining time.\n",
      "\t-6.1787\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.12s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.35s of the 163.35s of remaining time.\n",
      "\t-5.4513\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 151.41s of the 151.41s of remaining time.\n",
      "\t-5.8765\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 148.65s of the 148.64s of remaining time.\n",
      "\t-8.8536\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.0s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 132.51s of the 132.5s of remaining time.\n",
      "\t-5.7586\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 131.8s of the 131.8s of remaining time.\n",
      "\t-7.4355\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 83.09s of the 83.09s of remaining time.\n",
      "\t-5.6858\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 81.76s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.526, 'LightGBM': 0.221, 'LightGBMXT': 0.074, 'XGBoost': 0.042, 'NeuralNetTorch': 0.042, 'LightGBMLarge': 0.042, 'ExtraTreesMSE': 0.032, 'RandomForestMSE': 0.021}\n",
      "\t-5.3714\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 98.78s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_6\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_7\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       17.98 GB / 31.93 GB (56.3%)\n",
      "Disk Space Avail:   10.36 GB / 100.00 GB (10.4%)\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (63.9783942457408, -57.8192740914002, 0.7922, 20.16387)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18414.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-21.7715\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-22.104\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.35238\n",
      "[2000]\tvalid_set's rmse: 5.24538\n",
      "[3000]\tvalid_set's rmse: 5.25152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.2376\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.63s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 176.8s of the 176.8s of remaining time.\n",
      "\t-5.1863\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 176.02s of the 176.01s of remaining time.\n",
      "\t-5.474\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.72s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 169.28s of the 169.28s of remaining time.\n",
      "\t-5.1949\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.82s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 163.4s of the 163.39s of remaining time.\n",
      "\t-5.4409\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 160.72s of the 160.72s of remaining time.\n",
      "\t-6.7593\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.64s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 144.94s of the 144.93s of remaining time.\n",
      "\t-5.2768\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 144.29s of the 144.29s of remaining time.\n",
      "\t-5.5635\t = Validation score   (-root_mean_squared_error)\n",
      "\t62.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 82.21s of the 82.21s of remaining time.\n",
      "\t-5.348\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 81.03s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM': 0.403, 'NeuralNetTorch': 0.224, 'CatBoost': 0.194, 'LightGBMXT': 0.149, 'XGBoost': 0.03}\n",
      "\t-5.083\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 99.46s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_7\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_8\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.04 GB / 31.93 GB (56.5%)\n",
      "Disk Space Avail:   10.36 GB / 100.00 GB (10.4%)\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (151.406991529029, -145.107574671385, -0.53653, 52.57951)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18474.96 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-57.2771\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.8s of the 179.79s of remaining time.\n",
      "\t-57.9938\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 8.20565\n",
      "[2000]\tvalid_set's rmse: 7.84799\n",
      "[3000]\tvalid_set's rmse: 7.76055\n",
      "[4000]\tvalid_set's rmse: 7.7386\n",
      "[5000]\tvalid_set's rmse: 7.75785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-7.7293\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.09s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 175.2s of the 175.2s of remaining time.\n",
      "\t-7.4817\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 174.62s of the 174.62s of remaining time.\n",
      "\t-7.9841\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.53s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 168.1s of the 168.1s of remaining time.\n",
      "\t-7.3445\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 162.74s of the 162.74s of remaining time.\n",
      "\t-7.6913\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.7s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 160.05s of the 160.05s of remaining time.\n",
      "\t-9.821\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 143.22s of the 143.22s of remaining time.\n",
      "\t-7.4751\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 142.61s of the 142.61s of remaining time.\n",
      "\t-8.5317\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 93.08s of the 93.07s of remaining time.\n",
      "\t-7.566\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 91.86s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.423, 'XGBoost': 0.205, 'LightGBM': 0.141, 'NeuralNetTorch': 0.128, 'ExtraTreesMSE': 0.064, 'LightGBMXT': 0.026, 'NeuralNetFastAI': 0.013}\n",
      "\t-7.2144\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 88.62s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_8\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_9\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.02 GB / 31.93 GB (56.4%)\n",
      "Disk Space Avail:   9.53 GB / 100.00 GB (9.5%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (67.1934659250214, -59.3038389674677, 0.38456, 19.67882)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18455.53 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-20.8284\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.78s of remaining time.\n",
      "\t-21.0096\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.67s of the 179.67s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.94877\n",
      "[2000]\tvalid_set's rmse: 4.90872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.9044\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.14s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 177.31s of the 177.31s of remaining time.\n",
      "\t-4.8751\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 176.53s of the 176.52s of remaining time.\n",
      "\t-5.182\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.75s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 169.38s of the 169.38s of remaining time.\n",
      "\t-4.7858\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 165.43s of the 165.42s of remaining time.\n",
      "\t-5.0114\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 162.43s of the 162.42s of remaining time.\n",
      "\t-6.0765\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 145.96s of the 145.96s of remaining time.\n",
      "\t-4.9333\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 145.3s of the 145.3s of remaining time.\n",
      "\t-5.3576\t = Validation score   (-root_mean_squared_error)\n",
      "\t66.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 79.19s of the 79.19s of remaining time.\n",
      "\t-5.0204\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 77.66s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.565, 'LightGBM': 0.163, 'LightGBMXT': 0.152, 'ExtraTreesMSE': 0.054, 'NeuralNetTorch': 0.054, 'XGBoost': 0.011}\n",
      "\t-4.7628\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 102.82s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_9\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_10\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       17.88 GB / 31.93 GB (56.0%)\n",
      "Disk Space Avail:   9.49 GB / 100.00 GB (9.5%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (156.422187038181, -153.648903851311, -1.0105, 53.22841)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18313.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-57.4042\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.78s of the 179.78s of remaining time.\n",
      "\t-58.1089\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.67s of the 179.67s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.66077\n",
      "[2000]\tvalid_set's rmse: 6.26145\n",
      "[3000]\tvalid_set's rmse: 6.12031\n",
      "[4000]\tvalid_set's rmse: 6.03803\n",
      "[5000]\tvalid_set's rmse: 5.98787\n",
      "[6000]\tvalid_set's rmse: 5.9683\n",
      "[7000]\tvalid_set's rmse: 5.95408\n",
      "[8000]\tvalid_set's rmse: 5.94405\n",
      "[9000]\tvalid_set's rmse: 5.94522\n",
      "[10000]\tvalid_set's rmse: 5.93574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.9341\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.04s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 170.45s of the 170.45s of remaining time.\n",
      "\t-5.6649\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 169.67s of the 169.67s of remaining time.\n",
      "\t-6.3971\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.54s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.09s of the 163.09s of remaining time.\n",
      "\t-5.5297\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.93s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 153.09s of the 153.09s of remaining time.\n",
      "\t-5.9455\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 149.8s of the 149.8s of remaining time.\n",
      "\t-9.4295\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.56s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 133.09s of the 133.08s of remaining time.\n",
      "\t-5.7366\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 132.24s of the 132.24s of remaining time.\n",
      "\t-7.7817\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.16s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 89.01s of the 89.01s of remaining time.\n",
      "\t-5.7105\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 87.27s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.487, 'LightGBM': 0.179, 'XGBoost': 0.141, 'LightGBMLarge': 0.09, 'ExtraTreesMSE': 0.051, 'LightGBMXT': 0.038, 'NeuralNetTorch': 0.013}\n",
      "\t-5.4345\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 93.21s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_10\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_11\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.10 GB / 31.93 GB (56.7%)\n",
      "Disk Space Avail:   8.66 GB / 100.00 GB (8.7%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (61.0137371061435, -58.1689092525066, 0.58259, 19.97027)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18521.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.92s of the 179.92s of remaining time.\n",
      "\t-21.5329\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.78s of the 179.78s of remaining time.\n",
      "\t-21.6544\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.66s of the 179.66s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.26683\n",
      "[2000]\tvalid_set's rmse: 4.15512\n",
      "[3000]\tvalid_set's rmse: 4.14593\n",
      "[4000]\tvalid_set's rmse: 4.14508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.1397\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 175.71s of the 175.71s of remaining time.\n",
      "\t-4.1645\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 175.05s of the 175.05s of remaining time.\n",
      "\t-4.405\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.84s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 168.0s of the 168.0s of remaining time.\n",
      "\t-3.9959\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 163.18s of the 163.18s of remaining time.\n",
      "\t-4.2616\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.73s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 159.94s of the 159.94s of remaining time.\n",
      "\t-5.6661\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.13s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 143.66s of the 143.66s of remaining time.\n",
      "\t-4.1678\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 143.05s of the 143.05s of remaining time.\n",
      "\t-4.3352\t = Validation score   (-root_mean_squared_error)\n",
      "\t70.4s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 72.56s of the 72.56s of remaining time.\n",
      "\t-4.234\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.92s of the 71.3s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.549, 'NeuralNetTorch': 0.176, 'LightGBMXT': 0.132, 'XGBoost': 0.11, 'ExtraTreesMSE': 0.033}\n",
      "\t-3.9551\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 109.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_11\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_12\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.18 GB / 31.93 GB (56.9%)\n",
      "Disk Space Avail:   8.20 GB / 100.00 GB (8.2%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (162.1486850567, -150.260530445322, -0.57142, 53.98077)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18617.40 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.93s of the 179.93s of remaining time.\n",
      "\t-57.5618\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-58.3711\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.67s of the 179.67s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.44337\n",
      "[2000]\tvalid_set's rmse: 5.93741\n",
      "[3000]\tvalid_set's rmse: 5.74325\n",
      "[4000]\tvalid_set's rmse: 5.61724\n",
      "[5000]\tvalid_set's rmse: 5.55479\n",
      "[6000]\tvalid_set's rmse: 5.50543\n",
      "[7000]\tvalid_set's rmse: 5.46915\n",
      "[8000]\tvalid_set's rmse: 5.44984\n",
      "[9000]\tvalid_set's rmse: 5.4323\n",
      "[10000]\tvalid_set's rmse: 5.43049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.4295\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.93s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 170.51s of the 170.51s of remaining time.\n",
      "\t-5.1813\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 169.62s of the 169.62s of remaining time.\n",
      "\t-5.7633\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 162.77s of the 162.77s of remaining time.\n",
      "\t-5.0176\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.45s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 153.25s of the 153.25s of remaining time.\n",
      "\t-5.4804\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 150.51s of the 150.51s of remaining time.\n",
      "\t-9.4029\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 134.02s of the 134.02s of remaining time.\n",
      "\t-5.3697\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 133.18s of the 133.17s of remaining time.\n",
      "\t-7.6729\t = Validation score   (-root_mean_squared_error)\n",
      "\t45.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 87.15s of the 87.14s of remaining time.\n",
      "\t-5.2876\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.93s of the 85.72s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.567, 'LightGBM': 0.247, 'ExtraTreesMSE': 0.052, 'RandomForestMSE': 0.041, 'XGBoost': 0.041, 'LightGBMXT': 0.031, 'NeuralNetTorch': 0.021}\n",
      "\t-4.9433\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 94.77s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_12\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_13\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.46 GB / 31.93 GB (57.8%)\n",
      "Disk Space Avail:   7.78 GB / 100.00 GB (7.8%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (68.0803483490063, -60.1070939552377, 0.37562, 19.77892)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18900.43 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.93s of remaining time.\n",
      "\t-21.5756\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.64s of the 179.64s of remaining time.\n",
      "\t-21.7892\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.53s of the 179.53s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.55567\n",
      "[2000]\tvalid_set's rmse: 3.27332\n",
      "[3000]\tvalid_set's rmse: 3.20914\n",
      "[4000]\tvalid_set's rmse: 3.17966\n",
      "[5000]\tvalid_set's rmse: 3.15633\n",
      "[6000]\tvalid_set's rmse: 3.15466\n",
      "[7000]\tvalid_set's rmse: 3.15643\n",
      "[8000]\tvalid_set's rmse: 3.15789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.1531\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.3s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 172.67s of the 172.67s of remaining time.\n",
      "\t-3.1168\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 171.76s of the 171.76s of remaining time.\n",
      "\t-3.3961\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.48s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 165.32s of the 165.32s of remaining time.\n",
      "\t-2.9974\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.02s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 159.24s of the 159.23s of remaining time.\n",
      "\t-3.2756\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 156.35s of the 156.35s of remaining time.\n",
      "\t-4.1907\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.32s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 140.89s of the 140.88s of remaining time.\n",
      "\t-3.2242\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 140.1s of the 140.09s of remaining time.\n",
      "\t-3.6369\t = Validation score   (-root_mean_squared_error)\n",
      "\t50.13s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 89.88s of the 89.88s of remaining time.\n",
      "\t-3.1475\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 88.05s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.526, 'LightGBM': 0.147, 'LightGBMXT': 0.105, 'NeuralNetTorch': 0.095, 'LightGBMLarge': 0.074, 'ExtraTreesMSE': 0.053}\n",
      "\t-2.9603\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 92.44s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_13\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_14\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.53 GB / 31.93 GB (58.0%)\n",
      "Disk Space Avail:   7.74 GB / 100.00 GB (7.7%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (149.968150016529, -152.006700076432, -0.93549, 53.86471)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18976.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.91s of the 179.91s of remaining time.\n",
      "\t-58.4338\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.78s of the 179.78s of remaining time.\n",
      "\t-58.9499\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.67s of the 179.67s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.84881\n",
      "[2000]\tvalid_set's rmse: 6.31777\n",
      "[3000]\tvalid_set's rmse: 6.07572\n",
      "[4000]\tvalid_set's rmse: 5.92288\n",
      "[5000]\tvalid_set's rmse: 5.84278\n",
      "[6000]\tvalid_set's rmse: 5.79153\n",
      "[7000]\tvalid_set's rmse: 5.74964\n",
      "[8000]\tvalid_set's rmse: 5.73204\n",
      "[9000]\tvalid_set's rmse: 5.71637\n",
      "[10000]\tvalid_set's rmse: 5.71061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.71\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.6s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 171.01s of the 171.01s of remaining time.\n",
      "\t-5.2668\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.28356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.05s of the 170.05s of remaining time.\n",
      "\t-5.7651\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.09s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.57s of the 163.57s of remaining time.\n",
      "\t-5.1142\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 135.39s of the 135.39s of remaining time.\n",
      "\t-5.4136\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 132.85s of the 132.85s of remaining time.\n",
      "\t-10.5505\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.98s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 116.73s of the 116.73s of remaining time.\n",
      "\t-5.4571\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 115.72s of the 115.72s of remaining time.\n",
      "\t-7.5377\t = Validation score   (-root_mean_squared_error)\n",
      "\t47.12s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 68.52s of the 68.52s of remaining time.\n",
      "\t-5.3415\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.91s of the 66.85s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.542, 'LightGBM': 0.22, 'ExtraTreesMSE': 0.203, 'LightGBMLarge': 0.034}\n",
      "\t-5.0351\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 113.69s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_14\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_15\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.51 GB / 31.93 GB (58.0%)\n",
      "Disk Space Avail:   6.89 GB / 100.00 GB (6.9%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (65.2795850905641, -59.6505723471174, 0.72889, 19.79081)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    18950.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-21.8603\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.81s of the 179.81s of remaining time.\n",
      "\t-22.07\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.7s of the 179.7s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.25945\n",
      "[2000]\tvalid_set's rmse: 3.01757\n",
      "[3000]\tvalid_set's rmse: 2.93067\n",
      "[4000]\tvalid_set's rmse: 2.88984\n",
      "[5000]\tvalid_set's rmse: 2.87113\n",
      "[6000]\tvalid_set's rmse: 2.86003\n",
      "[7000]\tvalid_set's rmse: 2.85565\n",
      "[8000]\tvalid_set's rmse: 2.85323\n",
      "[9000]\tvalid_set's rmse: 2.85389\n",
      "[10000]\tvalid_set's rmse: 2.85659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.8514\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.52s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 171.32s of the 171.32s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 2.87071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-2.8645\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.07s of the 170.06s of remaining time.\n",
      "\t-3.2523\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.41s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.62s of the 163.62s of remaining time.\n",
      "\t-2.7933\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 144.84s of the 144.84s of remaining time.\n",
      "\t-3.0949\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 142.02s of the 142.02s of remaining time.\n",
      "\t-4.3294\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.03s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 126.85s of the 126.85s of remaining time.\n",
      "\t-2.9021\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 126.0s of the 126.0s of remaining time.\n",
      "\t-3.873\t = Validation score   (-root_mean_squared_error)\n",
      "\t26.42s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 99.5s of the 99.5s of remaining time.\n",
      "\t-2.959\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 97.66s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.446, 'LightGBMXT': 0.27, 'LightGBM': 0.149, 'XGBoost': 0.108, 'ExtraTreesMSE': 0.027}\n",
      "\t-2.7539\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 82.85s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_15\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_16\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.71 GB / 31.93 GB (58.6%)\n",
      "Disk Space Avail:   6.85 GB / 100.00 GB (6.9%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (152.202716740788, -151.449011521979, -1.84963, 52.8678)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19155.81 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-55.0732\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.8s of the 179.8s of remaining time.\n",
      "\t-55.2313\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.41137\n",
      "[2000]\tvalid_set's rmse: 5.90894\n",
      "[3000]\tvalid_set's rmse: 5.71885\n",
      "[4000]\tvalid_set's rmse: 5.60484\n",
      "[5000]\tvalid_set's rmse: 5.53324\n",
      "[6000]\tvalid_set's rmse: 5.47454\n",
      "[7000]\tvalid_set's rmse: 5.44183\n",
      "[8000]\tvalid_set's rmse: 5.41534\n",
      "[9000]\tvalid_set's rmse: 5.3995\n",
      "[10000]\tvalid_set's rmse: 5.38906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.3889\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.63s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 170.94s of the 170.94s of remaining time.\n",
      "\t-5.1885\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.0s of the 170.0s of remaining time.\n",
      "\t-5.941\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.16s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.36s of the 163.36s of remaining time.\n",
      "\t-4.9133\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.98s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 154.31s of the 154.31s of remaining time.\n",
      "\t-5.5048\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.57s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 151.81s of the 151.81s of remaining time.\n",
      "\t-9.3134\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.35s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 136.31s of the 136.31s of remaining time.\n",
      "\t-5.302\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 135.57s of the 135.57s of remaining time.\n",
      "\t-8.8358\t = Validation score   (-root_mean_squared_error)\n",
      "\t28.93s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 106.57s of the 106.57s of remaining time.\n",
      "\t-5.2131\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 104.94s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.692, 'LightGBM': 0.128, 'ExtraTreesMSE': 0.064, 'LightGBMLarge': 0.064, 'XGBoost': 0.038, 'LightGBMXT': 0.013}\n",
      "\t-4.8793\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 75.54s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_16\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_17\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.80 GB / 31.93 GB (58.9%)\n",
      "Disk Space Avail:   6.85 GB / 100.00 GB (6.9%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (62.4909263589483, -58.9202093651248, 0.61308, 19.68355)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19254.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-21.2857\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-21.5412\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 3.58438\n",
      "[2000]\tvalid_set's rmse: 3.41068\n",
      "[3000]\tvalid_set's rmse: 3.37799\n",
      "[4000]\tvalid_set's rmse: 3.36408\n",
      "[5000]\tvalid_set's rmse: 3.36329\n",
      "[6000]\tvalid_set's rmse: 3.37088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-3.3584\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 174.69s of the 174.69s of remaining time.\n",
      "\t-3.3278\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 173.91s of the 173.91s of remaining time.\n",
      "\t-3.626\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.49s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 167.44s of the 167.44s of remaining time.\n",
      "\t-3.2698\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.64s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 142.72s of the 142.72s of remaining time.\n",
      "\t-3.5264\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 140.19s of the 140.19s of remaining time.\n",
      "\t-5.4636\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.15s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 124.9s of the 124.9s of remaining time.\n",
      "\t-3.341\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 124.18s of the 124.18s of remaining time.\n",
      "\t-3.8886\t = Validation score   (-root_mean_squared_error)\n",
      "\t79.61s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 44.49s of the 44.49s of remaining time.\n",
      "\t-3.447\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 43.01s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.391, 'LightGBM': 0.184, 'LightGBMXT': 0.172, 'XGBoost': 0.161, 'NeuralNetTorch': 0.057, 'ExtraTreesMSE': 0.034}\n",
      "\t-3.2153\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 137.48s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_17\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_18\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.86 GB / 31.93 GB (59.1%)\n",
      "Disk Space Avail:   5.99 GB / 100.00 GB (6.0%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (152.840553199924, -152.821031325876, -1.39451, 53.49928)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19311.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-58.2302\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.8s of the 179.8s of remaining time.\n",
      "\t-58.4789\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.69s of the 179.69s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.31729\n",
      "[2000]\tvalid_set's rmse: 5.77079\n",
      "[3000]\tvalid_set's rmse: 5.56744\n",
      "[4000]\tvalid_set's rmse: 5.48002\n",
      "[5000]\tvalid_set's rmse: 5.4242\n",
      "[6000]\tvalid_set's rmse: 5.39751\n",
      "[7000]\tvalid_set's rmse: 5.37511\n",
      "[8000]\tvalid_set's rmse: 5.37056\n",
      "[9000]\tvalid_set's rmse: 5.36076\n",
      "[10000]\tvalid_set's rmse: 5.36478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.3592\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.55s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 171.19s of the 171.19s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.1739\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.19s of the 170.19s of remaining time.\n",
      "\t-5.7347\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.17s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.87s of the 163.87s of remaining time.\n",
      "\t-4.9151\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 149.92s of the 149.92s of remaining time.\n",
      "\t-5.3593\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 147.42s of the 147.42s of remaining time.\n",
      "\t-9.3556\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.34s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 131.89s of the 131.89s of remaining time.\n",
      "\t-5.2827\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 131.05s of the 131.05s of remaining time.\n",
      "\t-7.3835\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 101.92s of the 101.92s of remaining time.\n",
      "\t-5.2139\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 100.4s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.6, 'ExtraTreesMSE': 0.129, 'XGBoost': 0.118, 'LightGBMLarge': 0.082, 'LightGBMXT': 0.047, 'LightGBM': 0.024}\n",
      "\t-4.8549\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 80.09s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_18\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_19\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.89 GB / 31.93 GB (59.1%)\n",
      "Disk Space Avail:   5.12 GB / 100.00 GB (5.1%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (62.5439266439571, -58.7829762008587, 0.90809, 20.1822)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19341.11 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-22.1653\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-22.3685\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.67s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.11364\n",
      "[2000]\tvalid_set's rmse: 5.01377\n",
      "[3000]\tvalid_set's rmse: 4.98087\n",
      "[4000]\tvalid_set's rmse: 4.97208\n",
      "[5000]\tvalid_set's rmse: 4.98517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.9685\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.21s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 175.11s of the 175.11s of remaining time.\n",
      "\t-4.965\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 174.51s of the 174.5s of remaining time.\n",
      "\t-5.1395\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 167.37s of the 167.37s of remaining time.\n",
      "\t-4.9467\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 162.86s of the 162.86s of remaining time.\n",
      "\t-5.041\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 160.19s of the 160.19s of remaining time.\n",
      "\t-6.329\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.04s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 144.98s of the 144.98s of remaining time.\n",
      "\t-4.9309\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 144.34s of the 144.33s of remaining time.\n",
      "\t-5.4153\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.11s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 101.15s of the 101.14s of remaining time.\n",
      "\t-5.101\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 99.84s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost': 0.34, 'LightGBMXT': 0.25, 'ExtraTreesMSE': 0.17, 'CatBoost': 0.13, 'NeuralNetTorch': 0.09, 'LightGBM': 0.02}\n",
      "\t-4.8283\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 80.66s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_19\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_20\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.93 GB / 31.93 GB (59.3%)\n",
      "Disk Space Avail:   5.12 GB / 100.00 GB (5.1%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (157.476324078749, -150.706565853656, -1.03579, 53.46669)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19382.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-57.6838\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.8s of the 179.79s of remaining time.\n",
      "\t-58.3067\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.54s of the 179.54s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.87909\n",
      "[2000]\tvalid_set's rmse: 6.24655\n",
      "[3000]\tvalid_set's rmse: 5.97893\n",
      "[4000]\tvalid_set's rmse: 5.8342\n",
      "[5000]\tvalid_set's rmse: 5.77124\n",
      "[6000]\tvalid_set's rmse: 5.72109\n",
      "[7000]\tvalid_set's rmse: 5.70004\n",
      "[8000]\tvalid_set's rmse: 5.67727\n",
      "[9000]\tvalid_set's rmse: 5.67689\n",
      "[10000]\tvalid_set's rmse: 5.66522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.6651\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.52s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 170.79s of the 170.79s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.36882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.3598\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 169.55s of the 169.55s of remaining time.\n",
      "\t-5.9353\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.16s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 162.63s of the 162.63s of remaining time.\n",
      "\t-5.1174\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 150.67s of the 150.67s of remaining time.\n",
      "\t-5.5234\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 147.59s of the 147.59s of remaining time.\n",
      "\t-8.3239\t = Validation score   (-root_mean_squared_error)\n",
      "\t15.11s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 132.29s of the 132.29s of remaining time.\n",
      "\t-5.4489\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 131.48s of the 131.48s of remaining time.\n",
      "\t-7.3493\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.52s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 86.88s of the 86.87s of remaining time.\n",
      "\t-5.4091\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 85.06s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.598, 'LightGBM': 0.155, 'ExtraTreesMSE': 0.124, 'XGBoost': 0.052, 'NeuralNetTorch': 0.052, 'LightGBMLarge': 0.021}\n",
      "\t-5.0506\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 95.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_20\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_21\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       18.86 GB / 31.93 GB (59.1%)\n",
      "Disk Space Avail:   4.28 GB / 100.00 GB (4.3%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (64.2451372562376, -56.316810140042, 0.90091, 20.05224)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19315.02 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-21.1859\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.65s of the 179.65s of remaining time.\n",
      "\t-21.5044\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.54s of the 179.54s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.58522\n",
      "[2000]\tvalid_set's rmse: 5.57193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.5659\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.77s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 177.58s of the 177.58s of remaining time.\n",
      "\t-5.5496\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 176.91s of the 176.91s of remaining time.\n",
      "\t-5.814\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.36s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 170.51s of the 170.51s of remaining time.\n",
      "\t-5.4662\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 166.09s of the 166.08s of remaining time.\n",
      "\t-5.7551\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 155.36s of the 155.36s of remaining time.\n",
      "\t-6.6247\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.9s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 140.31s of the 140.31s of remaining time.\n",
      "\t-5.5851\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 139.73s of the 139.73s of remaining time.\n",
      "\t-5.7769\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 80.0s of the 80.0s of remaining time.\n",
      "\t-5.5787\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 78.91s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.449, 'NeuralNetTorch': 0.192, 'XGBoost': 0.167, 'LightGBMLarge': 0.115, 'LightGBMXT': 0.077}\n",
      "\t-5.411\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 101.72s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_21\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_22\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       19.04 GB / 31.93 GB (59.6%)\n",
      "Disk Space Avail:   3.41 GB / 100.00 GB (3.4%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (160.283327729347, -152.080151527062, -1.06111, 53.02649)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19503.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.93s of remaining time.\n",
      "\t-56.3811\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.75s of the 179.75s of remaining time.\n",
      "\t-56.7147\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.49s of the 179.48s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 8.01268\n",
      "[2000]\tvalid_set's rmse: 7.50479\n",
      "[3000]\tvalid_set's rmse: 7.339\n",
      "[4000]\tvalid_set's rmse: 7.23726\n",
      "[5000]\tvalid_set's rmse: 7.18786\n",
      "[6000]\tvalid_set's rmse: 7.14887\n",
      "[7000]\tvalid_set's rmse: 7.1323\n",
      "[8000]\tvalid_set's rmse: 7.11431\n",
      "[9000]\tvalid_set's rmse: 7.10927\n",
      "[10000]\tvalid_set's rmse: 7.10115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-7.1012\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.6s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 170.57s of the 170.57s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.77735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-6.7404\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 169.57s of the 169.56s of remaining time.\n",
      "\t-7.2493\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.91s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 163.19s of the 163.18s of remaining time.\n",
      "\t-6.7351\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.32s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 157.78s of the 157.78s of remaining time.\n",
      "\t-7.0409\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 154.96s of the 154.96s of remaining time.\n",
      "\t-9.6149\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.83s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 139.97s of the 139.97s of remaining time.\n",
      "\t-6.9678\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 139.19s of the 139.18s of remaining time.\n",
      "\t-8.0817\t = Validation score   (-root_mean_squared_error)\n",
      "\t62.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 76.6s of the 76.59s of remaining time.\n",
      "\t-6.8225\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 75.01s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.389, 'LightGBM': 0.333, 'LightGBMLarge': 0.144, 'ExtraTreesMSE': 0.044, 'LightGBMXT': 0.033, 'RandomForestMSE': 0.033, 'NeuralNetTorch': 0.022}\n",
      "\t-6.5861\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 105.5s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_22\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_23\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       19.06 GB / 31.93 GB (59.7%)\n",
      "Disk Space Avail:   3.41 GB / 100.00 GB (3.4%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (64.4827738016441, -56.0313361991621, 0.60956, 19.93423)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19513.69 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-21.0494\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.79s of the 179.79s of remaining time.\n",
      "\t-21.2379\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.68s of the 179.68s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.08586\n",
      "[2000]\tvalid_set's rmse: 4.98794\n",
      "[3000]\tvalid_set's rmse: 4.98358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.9796\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.84s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 176.55s of the 176.55s of remaining time.\n",
      "\t-4.9441\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 175.82s of the 175.82s of remaining time.\n",
      "\t-5.1861\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.21s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 169.65s of the 169.65s of remaining time.\n",
      "\t-4.9142\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.92s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 164.64s of the 164.64s of remaining time.\n",
      "\t-5.1714\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.57s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 161.94s of the 161.94s of remaining time.\n",
      "\t-6.2725\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.93s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 146.86s of the 146.85s of remaining time.\n",
      "\t-5.0041\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 146.21s of the 146.21s of remaining time.\n",
      "\t-5.6787\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.43s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 101.7s of the 101.7s of remaining time.\n",
      "\t-5.0633\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.6s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 99.8s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.338, 'LightGBM': 0.279, 'LightGBMXT': 0.206, 'XGBoost': 0.103, 'NeuralNetTorch': 0.074}\n",
      "\t-4.8587\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 80.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_23\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_24\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       19.06 GB / 31.93 GB (59.7%)\n",
      "Disk Space Avail:   1.76 GB / 100.00 GB (1.8%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (157.034532578179, -151.252624231257, -0.80657, 52.30985)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19519.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-56.8184\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.78s of the 179.78s of remaining time.\n",
      "\t-57.3813\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.59s of the 179.59s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 6.68265\n",
      "[2000]\tvalid_set's rmse: 6.12134\n",
      "[3000]\tvalid_set's rmse: 5.9006\n",
      "[4000]\tvalid_set's rmse: 5.79268\n",
      "[5000]\tvalid_set's rmse: 5.71359\n",
      "[6000]\tvalid_set's rmse: 5.67945\n",
      "[7000]\tvalid_set's rmse: 5.66232\n",
      "[8000]\tvalid_set's rmse: 5.6535\n",
      "[9000]\tvalid_set's rmse: 5.64976\n",
      "[10000]\tvalid_set's rmse: 5.64118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.6391\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.55s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 170.99s of the 170.99s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 5.45496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-5.4506\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 170.0s of the 170.0s of remaining time.\n",
      "\t-6.0472\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 164.06s of the 164.06s of remaining time.\n",
      "\t-5.241\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 151.16s of the 151.16s of remaining time.\n",
      "\t-5.6776\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 148.63s of the 148.63s of remaining time.\n",
      "\t-9.5638\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.96s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 133.52s of the 133.51s of remaining time.\n",
      "\t-5.6372\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 132.7s of the 132.7s of remaining time.\n",
      "\t-7.3528\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.66s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 94.95s of the 94.95s of remaining time.\n",
      "\t-5.5373\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 93.4s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.585, 'LightGBM': 0.2, 'ExtraTreesMSE': 0.123, 'LightGBMXT': 0.046, 'LightGBMLarge': 0.031, 'NeuralNetFastAI': 0.015}\n",
      "\t-5.1797\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 87.23s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_24\")\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"agModels-R_25\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          12\n",
      "Memory Avail:       19.14 GB / 31.93 GB (59.9%)\n",
      "Disk Space Avail:   0.89 GB / 100.00 GB (0.9%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "Train Data Rows:    17920\n",
      "Train Data Columns: 4\n",
      "Label Column:       torque_rotor\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (62.407655707508, -55.3637331501389, 0.32019, 19.65401)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    19602.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 4 | ['rotor_posn', 'stator_exc_0', 'stator_exc_U', 'stator_exc_D']\n",
      "\t0.0s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.55 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 16128, Val Rows: 1792\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 179.94s of the 179.94s of remaining time.\n",
      "\t-21.2283\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 179.78s of the 179.78s of remaining time.\n",
      "\t-21.4453\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 179.66s of the 179.66s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 4.46409\n",
      "[2000]\tvalid_set's rmse: 4.34013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-4.331\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.35s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 176.86s of the 176.86s of remaining time.\n",
      "\t-4.2612\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 176.21s of the 176.21s of remaining time.\n",
      "\t-4.5299\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.2s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 169.82s of the 169.82s of remaining time.\n",
      "\t-4.1159\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 162.51s of the 162.51s of remaining time.\n",
      "\t-4.4008\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.55s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 160.0s of the 160.0s of remaining time.\n",
      "\t-6.2609\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.89s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 144.96s of the 144.96s of remaining time.\n",
      "\t-4.2921\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 144.36s of the 144.36s of remaining time.\n",
      "\t-5.0771\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.99s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 119.28s of the 119.28s of remaining time.\n",
      "\t-4.4196\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 179.94s of the 117.74s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.793, 'ExtraTreesMSE': 0.086, 'LightGBM': 0.069, 'LightGBMXT': 0.052}\n",
      "\t-4.1094\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 62.87s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-R_25\")\n"
     ]
    }
   ],
   "source": [
    "for rotor in rotor_pole_position:\n",
    "    rotor_id = int(rotor[2:])\n",
    "    if rotor_id > 2 and rotor_id < 28- 2:\n",
    "        rotor_data = data_ML_all[rotor]\n",
    "        X_features = rotor_data.drop('torque_rotor', axis=1)\n",
    "        target = rotor_data['torque_rotor']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_features, target, test_size=0.2, random_state=42)\n",
    "        x = X_features.columns\n",
    "        y = 'torque_rotor'\n",
    "\n",
    "        train_data = pd.concat([X_train, y_train], axis=1)\n",
    "        test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "        train_data = TabularDataset(train_data)\n",
    "        predictor = TabularPredictor(label=y,\n",
    "                                    path=f\"agModels-{rotor}\").fit(train_data,\n",
    "                                                                 time_limit=180)\n",
    "\n",
    "        test_data = TabularDataset(test_data)\n",
    "        performance = predictor.evaluate(test_data)\n",
    "\n",
    "        leaderboard = predictor.leaderboard(test_data)\n",
    "        leaderboard.to_csv(f\"{rotor}_leader_board.csv\")\n",
    "\n",
    "        with open(f\"{rotor}_gluon.log\", \"w\") as file:\n",
    "            file.write(str(performance))\n",
    "            file.write(str({'Rotor': rotor, 'path': predictor.path}))\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3193350-e0a0-4c42-9aeb-f9bacd3852b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938e002-7870-4e60-b1b3-bfd1990049a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c19be-dbbf-4c5f-b287-45a67501e3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "750fd516-f0d0-447c-9bbd-adf865d20500",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4101b-562b-41eb-8430-0e71c725d599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6e572-0692-4839-9093-da3e3e9c05b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c53419b-15d2-481c-9dcf-37b338da3791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603729ad-b882-4a69-be68-a8817e170ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
